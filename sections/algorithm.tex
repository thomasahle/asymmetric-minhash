%! TEX root = ../aminhash.tex

\section{Implementation Details}\label{sec:alg}

While the algorithm is simple conceptually, there are a few tricks to making it run as fast as the classical MinHash sketch.\footnote{We don't strive to be faster than the classical estimator for a fixed $K$, but for a given recall we can be faster, since our $K$ can be smaller.}

\begin{algorithm}
   \caption{Given a query $X\subseteq [u]$ and a database $D\in [0,1]^{n\times K}$ of sketches of sets $Y_1,\dots\subseteq [u]$, the algorithm estimates the similarity with each $Y_i$.}
   \label{alg:query}
   \begin{algorithmic}[1]
      \For{$j=1$ to $K$}
         \State $H_j \gets \text{sorted}(\{h_j(x) : x \in X\})$
      \EndFor
      \State Initialize a max-heap.
      \For{$i=1$ to $n$}
         %\Comment{Number of contained values, minner values and sum of hashes.}
         \State $C, M, R \gets 0, 0, 0$
         \For{$i=1$ to $K$}
         \State $R \gets R + D_{i,j}$
            \State $C\gets C + [D_{i,j} \in H_j]$ \label{line:contains}
            \Comment{Done by single table lookup}
            \State $M \gets M + \sum_{r\in H_j} [r < D_{i,j}]$ \label{line:prefix}
         \EndFor
         \State $y \gets |Y_i|$
         \Comment{Assuming the set sizes are stored}
         \State $v \gets \min\{\frac{C|X|}{C+M},\frac{Cy}{K}\}$
         \Comment{Minner estimator}
         \For{$i=1$ to Newtons}
            \Comment{Optional refinement}
            \State $\nu \gets \frac{R/u + C/(v+1) - (K-C)/(y-v+1) - M/(|X|-v+1)}
            {C/(v+1)^2 + (K-C)/(y-v+1)^2 + M/(|X|-v+1)^2}$
            \State $v \gets \min\{\max\{0,v\}, |X|, y\}$
         \EndFor
         \State $j \gets v/(|X| + y - v)$ \Comment{If Jaccard similarity is required.}
         \State Push $(j,i)$ to the max-heap if big enough.
      \EndFor
   \end{algorithmic}
\end{algorithm}

In \cref{alg:query} we show how one may use our estimator to do a fast scan through a database.
We assume $D_{i,j}\in[0,1]$ stores the minimum hash value of $Y_i$ under hash function $h_j$.
It is perhaps more typical to have $D_{i,j}$ store the $\argmin_{y\in Y_i}h(y)$, but in that case one can simply compute $h(D_{i,j})$ at runtime, which is usually a very cheap function.
The MinHash survey of Cohen~\cite{DBLP:reference/algo/Cohen16b} discusses many very efficient ways of storing MinHash values.

In \cref{alg:query} we start by hashing each element of $X$ under the $K$ hash functions.
We sort the resulting values, to be able to perform \cref{line:contains} and \cref{line:prefix} more efficiently.
These lines respectively check if a given $Y$ hash-value is also in $X$, and counts how many hash-values from $X$ are smaller than the $Y$ hash-value.

There are many ways to perform these tasks.
If the range of $h$ is small, say under a million, we can precompute tables.
For large ranges, we can use that the $H_j$'s are sorted and binary search, which works for both tasks.
In practice, if $|Y|$ is not too much bigger than $|X|$, a linear scan of $H_j$, will yield the right position in constant time.
One can also use one of a plethora of fast prefix sum data structures, which are particularly simple since the values of $H_j$ are uniformly random.
% TODO: Mention that thing about makeing |X| buckets and precomputing the prefix sums?

Ideally we would like each value $D_{i,j}$ to take up just 4 bits.
If so, one can use the ``shuffle'' SIMD instruction to perform 16 or more table lookups in a single instruction.
This method, common in Product Quantization implementations~\cite{andre2019quicker}, has the potential to make our estimators as fast as the classical one, even per MinHash value, since the shuffle table fits in registers.

The reduction to 4 bits is possible because the ranks are heavily concentrated around $n_y/u$, and so have much lower entropy than the direct $\log_2 u$.
Using rounding to an exponential set of values, like $\{1, 2, 4, \dots\}$ corresponds to storing just the length of the rank, and provides a good approximation.
Another approach is the $b$-bit Minwise Hashing~\cite{li2010b} technique, which stores only the last $b$ bits of the rank.
